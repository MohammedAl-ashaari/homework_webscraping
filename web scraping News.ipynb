{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting feedparser\n",
      "  Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\eng-moal-ashaari\\anaconda3\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\eng-moal-ashaari\\anaconda3\\lib\\site-packages (4.9.3)\n",
      "Requirement already satisfied: lxml in c:\\users\\eng-moal-ashaari\\anaconda3\\lib\\site-packages (4.6.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\eng-moal-ashaari\\anaconda3\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\eng-moal-ashaari\\anaconda3\\lib\\site-packages (3.0.5)\n",
      "Collecting sgmllib3k\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\eng-moal-ashaari\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\eng-moal-ashaari\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\eng-moal-ashaari\\anaconda3\\lib\\site-packages (from requests) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eng-moal-ashaari\\anaconda3\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\eng-moal-ashaari\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\eng-moal-ashaari\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\eng-moal-ashaari\\anaconda3\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\eng-moal-ashaari\\anaconda3\\lib\\site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: jdcal in c:\\users\\eng-moal-ashaari\\anaconda3\\lib\\site-packages (from openpyxl) (1.4.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\eng-moal-ashaari\\anaconda3\\lib\\site-packages (from openpyxl) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\eng-moal-ashaari\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6070 sha256=ea55ef783dde61f6a09b625dd16cbab807c52d490a3f313d6c6a08f622255457\n",
      "  Stored in directory: c:\\users\\eng-moal-ashaari\\appdata\\local\\pip\\cache\\wheels\\83\\63\\2f\\117884c3b19d46b64d3d61690333aa80c88dc14050e269c546\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser\n",
      "Successfully installed feedparser-6.0.12 sgmllib3k-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install feedparser requests beautifulsoup4 lxml pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: RSS ...\n",
      "\n",
      "=== Ø£Ø­Ø¯Ø« Ø§Ù„Ø£Ø®Ø¨Ø§Ø± (Ø£ÙˆÙ„ 20) ===\n",
      "\n",
      "[1] Ù…Ø¯Ù† Ø§Ù„ÙƒÙˆÙ†ØºÙˆ Ø§Ù„Ù…ØªØ¶Ø±Ø±Ø© Ù…Ù† Ø¥ÙŠØ¨ÙˆÙ„Ø§ ØªØ­Øª Ø§Ù„Ø­Ø¬Ø± Ø§Ù„ØµØ­ÙŠ Ù…Ø¹ Ø§Ø±ØªÙØ§Ø¹ Ø¹Ø¯Ø¯ Ø§Ù„Ø¥ØµØ§Ø¨Ø§Øª\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T23:14:00+03:00\n",
      "Ù‚Ø³Ù…: health\n",
      "Ù…Ù„Ø®Øµ: Ù‚Ø§Ù„ Ù…Ø³Ø¤ÙˆÙ„ÙˆÙ† Ù‡Ø°Ø§ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø¥Ù† Ø§Ù„Ù…Ø¯Ù† Ø§Ù„Ù…ØªØ£Ø«Ø±Ø© Ø¨Ø£Ø­Ø¯Ø« ØªÙØ´ Ù„ÙˆØ¨Ø§Ø¡ Ø¥ÙŠØ¨ÙˆÙ„Ø§ ÙÙŠ Ø§Ù„ÙƒÙˆÙ†ØºÙˆ Ø£Ù‚Ø§Ù…Øª Ù†Ù‚Ø§Ø· ØªÙØªÙŠØ´ Ù„Ù„Ø­Ø¯ Ù…Ù† Ø­Ø±ÙƒØ© Ø§Ù„Ø³ÙƒØ§Ù†ØŒ Ù†Ø¸Ø±Ø§ Ù„Ø§Ø±ØªÙØ§Ø¹ Ø·ÙÙŠÙ ÙÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø¥ØµØ§Ø¨Ø§Øª ÙÙŠ ÙˆÙ‚Øª Ø­Ø°Ø± ÙÙŠÙ‡ Ø¹Ù…Ø§Ù„ Ø§Ù„Ø¥ØºØ§Ø«Ø© Ù…Ù† Ù†Ù‚Øµ Ø§Ù„ØªÙ…ÙˆÙŠÙ„.\n",
      "\n",
      "[2] ØªØ­Ø°ÙŠØ± Ù…Ù† Ø§Ø±ØªÙØ§Ø¹ ÙˆÙÙŠØ§Øª Ø§Ù„Ù…Ù„Ø§Ø±ÙŠØ§ Ù…Ø¹ ØªØ±Ø§Ø¬Ø¹ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø§Øª Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T23:11:00+03:00\n",
      "Ù‚Ø³Ù…: health\n",
      "Ù…Ù„Ø®Øµ: Ø­Ø°Ø± Ù…Ø¯ÙŠØ± Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ Ù„Ù…ÙƒØ§ÙØ­Ø© Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù…Ø¹Ø¯ÙŠØ©ØŒ Ø§Ù„Ø£Ø±Ø¨Ø¹Ø§Ø¡ØŒ Ù…Ù† Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø±ØªÙØ§Ø¹ ÙˆÙÙŠØ§Øª Ø§Ù„Ù…Ù„Ø§Ø±ÙŠØ§ Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø§Ù… Ø¨Ø³Ø¨Ø¨ ØªØ±Ø§Ø¬Ø¹ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø§Øª Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©.\n",
      "\n",
      "[3] Ø§Ù„Ø¹ÙÙˆ Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©: Ø§Ù„ØªÙ‡Ø¬ÙŠØ± Ø§Ù„Ø¬Ù…Ø§Ø¹ÙŠ Ù„Ø³ÙƒØ§Ù† ØºØ²Ø© ØºÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠ ÙˆÙ„Ø§ Ø¥Ù†Ø³Ø§Ù†ÙŠ\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T23:04:18+03:00\n",
      "Ù‚Ø³Ù…: news\n",
      "Ù…Ù„Ø®Øµ: Ø¯Ø¹Øª Ù…Ù†Ø¸Ù…Ø© Ø§Ù„Ø¹ÙÙˆ Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ÙÙˆØ±ÙŠ Ù„Ø£Ù…Ø± Ø§Ù„ØªÙ‡Ø¬ÙŠØ± Ø§Ù„Ø¬Ù…Ø§Ø¹ÙŠ Ø§Ù„Ø°ÙŠ Ø£ØµØ¯Ø±Ù‡ Ø¬ÙŠØ´Ù‡Ø§ Ù„Ø³ÙƒØ§Ù† Ù…Ø¯ÙŠÙ†Ø© ØºØ²Ø© Ù…Ø¹ ØªØµØ¹ÙŠØ¯ Ù‡Ø¬ÙˆÙ…Ù‡Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©ØŒ ÙˆØ£ÙƒØ¯Øª Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø± ÙŠÙØ§Ù‚Ù… Ù…Ø¹Ø§Ù†Ø§Ø© Ø§Ù„Ù…Ø¯Ù†ÙŠÙŠÙ† ÙˆØ³Ø· Ø¥Ø¨Ø§Ø¯Ø© Ø¬Ù…Ø§Ø¹ÙŠØ© Ù…Ø³ØªÙ…Ø±Ø©.\n",
      "\n",
      "[4] Ø£ÙˆØ±ÙˆØ¨Ø§ ØªÙ†Ø¯Ø¯ Ø¨Ø§Ø®ØªØ±Ø§Ù‚ Ù…Ø³ÙŠÙ‘Ø±Ø§Øª Ø£Ø¬ÙˆØ§Ø¡ Ø¨ÙˆÙ„Ù†Ø¯Ø§ ÙˆØ±ÙˆØ³ÙŠØ§ ØªÙ†ÙÙŠ Ù…Ø³Ø¤ÙˆÙ„ÙŠØªÙ‡Ø§\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T22:27:33+03:00\n",
      "Ù‚Ø³Ù…: video\n",
      "Ù…Ù„Ø®Øµ: Ù‚Ø§Ù„ Ø§Ù„Ø£Ù…ÙŠÙ† Ø§Ù„Ø¹Ø§Ù… Ù„Ø­Ù„Ù Ø´Ù…Ø§Ù„ Ø§Ù„Ø£Ø·Ù„Ø³ÙŠ (Ø§Ù„Ù†Ø§ØªÙˆ) Ù…Ø§Ø±Ùƒ Ø±ÙˆØªÙ‡ Ø¥Ù† Ø±Ø¯ Ø§Ù„Ø­Ù„Ù Ø¹Ù„Ù‰ Ø§Ù†ØªÙ‡Ø§Ùƒ Ø§Ù„Ø·Ø§Ø¦Ø±Ø§Øª Ø§Ù„Ù…Ø³ÙŠÙ‘Ø±Ø© Ø§Ù„Ø±ÙˆØ³ÙŠØ© Ù„Ù„Ø£Ø¬ÙˆØ§Ø¡ Ø§Ù„Ø¨ÙˆÙ„Ù†Ø¯ÙŠØ© Ù†Ø§Ø¬Ø­ Ù„Ù„ØºØ§ÙŠØ©ØŒ Ù…Ø¤ÙƒØ¯Ø§ Ø£Ù† Ø§Ù„Ù†Ø§ØªÙˆ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¯ÙØ§Ø¹ Ø¹Ù† ÙƒÙ„ Ø´Ø¨Ø± Ù…Ù† Ø£Ø±Ø§Ø¶ÙŠÙ‡.\n",
      "\n",
      "[5] Ù…Ù‚ØªÙ„ Ø§Ù„Ù…Ø¤Ø«Ø± Ø§Ù„Ø£Ù…ÙŠØ±ÙƒÙŠ ØªØ´Ø§Ø±Ù„ÙŠ ÙƒÙŠØ±Ùƒ ÙˆØªØ±Ø§Ù…Ø¨ ÙŠØµÙÙ‡ Ø¨Ù€\"Ø§Ù„Ø£Ø³Ø·ÙˆØ±ÙŠ Ø§Ù„Ø¹Ø¸ÙŠÙ…\"\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T22:22:03+03:00\n",
      "Ù‚Ø³Ù…: news\n",
      "Ù…Ù„Ø®Øµ: Ø£Ø¹Ù„Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ Ø§Ù„Ø£Ù…ÙŠØ±ÙƒÙŠØŒ Ù…Ø³Ø§Ø¡ Ø£Ù…Ø³ Ø§Ù„Ø£Ø±Ø¨Ø¹Ø§Ø¡ØŒ Ù…Ù‚ØªÙ„ ØªØ´Ø§Ø±Ù„ÙŠ ÙƒÙŠØ±Ùƒ Ø§Ù„Ù†Ø§Ø´Ø· ÙˆØ§Ù„Ù…Ø¤Ø«Ø± Ø¹Ù„Ù‰ Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ Ø¥Ø«Ø± ØªØ¹Ø±Ø¶Ù‡ Ù„Ø¥Ø·Ù„Ø§Ù‚ Ø§Ù„Ù†Ø§Ø± Ø®Ù„Ø§Ù„ Ù…Ø´Ø§Ø±ÙƒØªÙ‡ ÙÙŠ ÙØ¹Ø§Ù„ÙŠØ© Ø¨ÙˆÙ„Ø§ÙŠØ© ÙŠÙˆØªØ§ (ØºØ±Ø¨ÙŠ Ø§Ù„Ø¨Ù„Ø§Ø¯).\n",
      "\n",
      "[6] Ø£Ø¨Ø¹Ø§Ø¯ ÙˆØ¯Ù„Ø§Ù„Ø§Øª Ø§Ù„Ù‚ØµÙ Ø§Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠ Ø¹Ù„Ù‰ Ù‚Ø·Ø±\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T22:15:51+03:00\n",
      "Ù‚Ø³Ù…: video\n",
      "Ù…Ù„Ø®Øµ: Ù†Ø§Ù‚Ø´ Ø¨Ø±Ù†Ø§Ù…Ø¬ &quot;Ù…Ø³Ø§Ø± Ø§Ù„Ø£Ø­Ø¯Ø§Ø«&quot; ÙÙŠ Ø­Ù„Ù‚Ø© (2025/9/10) Ø£Ø¨Ø¹Ø§Ø¯ ÙˆØ¯Ù„Ø§Ù„Ø§Øª Ø§Ù„Ù‚ØµÙ Ø§Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠ Ø¹Ù„Ù‰ Ù‚Ø·Ø± ÙˆØªØ¯Ø§Ø¹ÙŠØ§ØªÙ‡ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†Ø¸ÙˆÙ…Ø© Ø§Ù„Ø®Ù„ÙŠØ¬ÙŠØ©ØŒ ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªÙŠ ÙŠØ±Ù…ÙŠ Ø¥Ù„ÙŠÙ‡Ø§ Ø±Ø¦ÙŠØ³ Ø§Ù„ÙˆØ²Ø±Ø§Ø¡ Ø§Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠ ÙÙŠ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©.\n",
      "\n",
      "[7] Ù…Ø§Ø°Ø§ Ø¨Ø¹Ø¯ Ø§ØªÙØ§Ù‚ Ø§Ø³ØªØ¦Ù†Ø§Ù Ø§Ù„ØªÙØªÙŠØ´ Ø¨ÙŠÙ† Ø¥ÙŠØ±Ø§Ù† ÙˆÙˆÙƒØ§Ù„Ø© Ø§Ù„Ø·Ø§Ù‚Ø© Ø§Ù„Ø°Ø±ÙŠØ©ØŸ\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T22:15:01+03:00\n",
      "Ù‚Ø³Ù…: video\n",
      "Ù…Ù„Ø®Øµ: Ø¨Ø¯Ø£ Ù…Ø­Ø§ÙØ¸Ùˆ Ø§Ù„ÙˆÙƒØ§Ù„Ø© Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© Ù„Ù„Ø·Ø§Ù‚Ø© Ø§Ù„Ø°Ø±ÙŠØ© ÙÙŠ ÙÙŠÙŠÙ†Ø§ Ù†Ù‚Ø§Ø´Ø§ØªÙ‡Ù… Ø¨Ø´Ø£Ù† Ø§ØªÙØ§Ù‚ Ø§Ø³ØªØ¦Ù†Ø§Ù Ø§Ù„ØªÙØªÙŠØ´ Ø§Ù„Ø°ÙŠ ÙˆÙ‚Ø¹ Ø¹Ù„ÙŠÙ‡ ÙÙŠ Ø§Ù„Ù‚Ø§Ù‡Ø±Ø© Ø§Ù„Ù…Ø¯ÙŠØ± Ø§Ù„Ø¹Ø§Ù… Ù„Ù„ÙˆÙƒØ§Ù„Ø© Ø±Ø§ÙØ§Ø¦ÙŠÙ„ ØºØ±ÙˆØ³ÙŠØŒ ÙˆÙˆØ²ÙŠØ± Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© Ø§Ù„Ø¥ÙŠØ±Ø§Ù†ÙŠ Ø¹Ø¨Ø§Ø³ Ø¹Ø±Ø§Ù‚Ø¬ÙŠ.\n",
      "\n",
      "[8] Ø§Ø­ØªØ¬Ø§Ø¬Ø§Øª ÙÙŠ Ø¨Ø§Ø±ÙŠØ³ ÙˆÙ…Ø¯Ù† ÙØ±Ù†Ø³ÙŠØ© Ø¶Ø¯ Ø³ÙŠØ§Ø³Ø§Øª Ù…Ø§ÙƒØ±ÙˆÙ† Ø§Ù„ØªÙ‚Ø´ÙÙŠØ©\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T22:13:01+03:00\n",
      "Ù‚Ø³Ù…: video\n",
      "Ù…Ù„Ø®Øµ: Ø´Ù‡Ø¯Øª ÙØ±Ù†Ø³Ø§ Ù…Ø¸Ø§Ù‡Ø±Ø§Øª ÙÙŠ Ø§Ù„Ø¹Ø§ØµÙ…Ø© Ø¨Ø§Ø±ÙŠØ³ ÙˆÙ…Ø¯Ù† Ø£Ø®Ø±Ù‰ Ø±ÙØ¶Ø§ Ù„Ù„ØªÙ‚Ø´Ù ÙˆØ§Ù„Ø³ÙŠØ§Ø³Ø§Øª Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© Ù„Ù„Ø±Ø¦ÙŠØ³ Ø¥ÙŠÙ…Ø§Ù†ÙˆÙŠÙ„ Ù…Ø§ÙƒØ±ÙˆÙ† ÙˆØ§Ù„Ø­ÙƒÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ¹Ø§Ù‚Ø¨Ø©.\n",
      "\n",
      "[9] Ù‡Ù„ ÙŠØ±ÙŠØ¯ Ù†ØªÙ†ÙŠØ§Ù‡Ùˆ Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ø®Ù„ÙŠØ¬ØŸ ÙˆÙ…Ø§ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù„Ø±Ø¯Ø¹Ù‡ØŸ\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T21:43:31+03:00\n",
      "Ù‚Ø³Ù…: politics\n",
      "Ù…Ù„Ø®Øµ: Ø§ØªÙÙ‚ Ø®Ø¨Ø±Ø§Ø¡ ÙÙŠ Ø§Ù„Ø´Ø£Ù† Ø§Ù„Ø®Ù„ÙŠØ¬ÙŠ Ø¹Ù„Ù‰ Ø£Ù† Ø§Ù„Ø¹Ø¯ÙˆØ§Ù† Ø§Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠ Ø¹Ù„Ù‰ Ù‚Ø·Ø± ÙŠØ³ØªÙ‡Ø¯Ù Ø¯ÙˆÙ„ Ø§Ù„Ø®Ù„ÙŠØ¬ Ø¨Ø£Ø³Ø±Ù‡Ø§ØŒ Ù…Ù…Ø§ ÙŠØªØ·Ù„Ø¨ Ø¶Ø±ÙˆØ±Ø© Ø§ØªØ®Ø§Ø° Ù‚Ø±Ø§Ø±Ø§Øª ÙˆØ¥Ø¬Ø±Ø§Ø¡ Ù…Ø±Ø§Ø¬Ø¹Ø§Øª ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø¸Ø± ÙÙŠ Ø§Ù„ØªØ­Ø§Ù„ÙØ§Øª Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©.\n",
      "\n",
      "[10] Ø§Ù„ÙƒØ§Ø¨ÙˆØ³ Ø§Ù„Ø£ÙƒØ¨Ø± Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ Ø§Ù„Ø¢Ù†\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T21:30:25+03:00\n",
      "Ù‚Ø³Ù…: opinions\n",
      "Ù…Ù„Ø®Øµ: Ù‡Ù†Ø§Ùƒ Ø­ØªÙ…ÙŠØ© Ù„Ø§Ù†ØªÙØ§Ø¶Ø© Ø¬Ø¯ÙŠØ¯Ø©ØŒ ÙˆÙ…Ù‡Ù…Ø§ Ø§Ø®ØªÙ„ÙØª Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ© Ù„Ø´ÙƒÙ„ Ø§Ù„Ø§Ù†ÙØ¬Ø§Ø± Ø§Ù„Ù…Ù‚Ø¨Ù„ØŒ ÙØ¥Ù† Ø§Ù„Ø«Ø§Ø¨Øª Ø£Ù† Ù…Ø§ Ø¨Ø¹Ø¯Ù‡ Ù„Ù† ÙŠÙƒÙˆÙ† ÙƒÙ…Ø§ Ù‚Ø¨Ù„Ù‡Ø› ÙˆØ³ÙŠÙÙƒØªØ¨ ÙØµÙ„Ø§ Ø¬Ø¯ÙŠØ¯Ø§ ÙÙŠ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚Ø¶ÙŠØ© Ø§Ù„ÙÙ„Ø³Ø·ÙŠÙ†ÙŠØ©ØŒ ÙˆØ¥Ù† ØºØ¯Ø§ Ù„Ù†Ø§Ø¸Ø±Ù‡ Ù‚Ø±ÙŠØ¨.\n",
      "\n",
      "[11] Ù‚Ø·Ø± ØªØ¤ÙƒØ¯ Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ù…Ø¯ÙŠØ± Ù…ÙƒØªØ¨ Ø®Ù„ÙŠÙ„ Ø§Ù„Ø­ÙŠØ© ÙÙŠ Ø§Ù„Ù‡Ø¬ÙˆÙ… Ø§Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠ\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T21:27:44+03:00\n",
      "Ù‚Ø³Ù…: news\n",
      "Ù…Ù„Ø®Øµ: Ø£ÙƒØ¯Øª ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ø§Ù„Ù‚Ø·Ø±ÙŠØ©ØŒ Ù…Ø³Ø§Ø¡ Ø£Ù…Ø³ Ø§Ù„Ø£Ø±Ø¨Ø¹Ø§Ø¡ØŒ Ù…Ù‚ØªÙ„ Ø¬Ù‡Ø§Ø¯ Ø±ÙŠØ§Ø­ Ø­Ø³Ù† Ù„Ø¨Ø¯ØŒ Ù…Ø¯ÙŠØ± Ù…ÙƒØªØ¨ Ø®Ù„ÙŠÙ„ Ø§Ù„Ø­ÙŠØ© Ø±Ø¦ÙŠØ³ Ø­Ø±ÙƒØ© Ø­Ù…Ø§Ø³ ÙÙŠ ØºØ²Ø© ÙˆØ±Ø¦ÙŠØ³ Ø§Ù„ÙˆÙØ¯ Ø§Ù„Ù…ÙØ§ÙˆØ¶ØŒ Ø¥Ø«Ø± Ù‡Ø¬ÙˆÙ… Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠ Ø§Ø³ØªÙ‡Ø¯Ù Ù…Ù‚Ø±Ø§Øª Ø³ÙƒÙ†ÙŠØ© ÙŠÙ‚ÙŠÙ… ÙÙŠÙ‡Ø§ Ù‚Ø§Ø¯Ø© Ù…Ù† Ø­Ù…Ø§Ø³.\n",
      "\n",
      "[12] Ù‚Ø·Ø±: Ù†Ø³ØªÙ†ÙƒØ± ØªØµØ±ÙŠØ­Ø§Øª Ù†ØªÙ†ÙŠØ§Ù‡Ùˆ Ø§Ù„Ù…ØªÙ‡ÙˆØ±Ø© ÙˆÙ†Ø¹Ù…Ù„ Ù…Ø¹ Ø´Ø±ÙƒØ§Ø¦Ù†Ø§ Ù„Ø¶Ù…Ø§Ù† Ù…Ø­Ø§Ø³Ø¨ØªÙ‡\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T21:17:20+03:00\n",
      "Ù‚Ø³Ù…: news\n",
      "Ù…Ù„Ø®Øµ: Ø§Ø³ØªÙ†ÙƒØ±Øª Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© Ø§Ù„Ù‚Ø·Ø±ÙŠØ© &quot;Ø¨Ø£Ø´Ø¯ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª&quot; Ø§Ù„ØªØµØ±ÙŠØ­Ø§Øª &quot;Ø§Ù„Ù…ØªÙ‡ÙˆØ±Ø©&quot; Ø§Ù„ØªÙŠ Ø£Ø¯Ù„Ù‰ Ø¨Ù‡Ø§ Ø±Ø¦ÙŠØ³ Ø§Ù„ÙˆØ²Ø±Ø§Ø¡ Ø§Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠ Ø¨Ø´Ø£Ù† Ø§Ø³ØªØ¶Ø§ÙØ© Ø§Ù„Ø¯ÙˆØ­Ø© Ù…ÙƒØªØ¨ Ø­Ø±ÙƒØ© Ø­Ù…Ø§Ø³ØŒ ÙˆØ¹Ø¨Ù‘Ø±Øª Ø§Ù„ÙˆØ²Ø§Ø±Ø© Ø¹Ù† Ø¥Ø¯Ø§Ù†ØªÙ‡Ø§ Ù„ØªÙ‡Ø¯ÙŠØ¯Ø§ØªÙ‡ Ø§Ù„ØµØ±ÙŠØ­Ø©.\n",
      "\n",
      "[13] Ø§Ù„Ø­Ø±Ø¨ Ø¹Ù„Ù‰ ØºØ²Ø© Ù…Ø¨Ø§Ø´Ø±.. Ø¹Ø´Ø±Ø§Øª Ø§Ù„Ø´Ù‡Ø¯Ø§Ø¡ ÙˆØ¥Ø¯Ø§Ù†Ø§Øª Ù…ØªÙˆØ§ØµÙ„Ø© Ù„Ù„Ù‡Ø¬ÙˆÙ… Ø¹Ù„Ù‰ Ù‚Ø·Ø±\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T21:09:40+03:00\n",
      "Ù‚Ø³Ù…: news\n",
      "Ù…Ù„Ø®Øµ: ÙÙŠ Ø§Ù„ÙŠÙˆÙ… Ø§Ù„Ù€706 Ù…Ù† Ø­Ø±Ø¨ Ø§Ù„Ø¥Ø¨Ø§Ø¯Ø© Ø¹Ù„Ù‰ ØºØ²Ø©ØŒ Ø£ÙØ§Ø¯Øª Ù…ØµØ§Ø¯Ø± ÙÙŠ Ù…Ø³ØªØ´ÙÙŠØ§Øª Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø¨Ø§Ø³ØªØ´Ù‡Ø§Ø¯ 72 ÙÙ„Ø³Ø·ÙŠÙ†ÙŠØ§ ÙÙŠ ØºØ§Ø±Ø§Øª Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø·Ø§Ø¹ Ù…Ù†Ø° ÙØ¬Ø± Ø§Ù„Ø£Ø±Ø¨Ø¹Ø§Ø¡ØŒ Ø¨ÙŠÙ†Ù‡Ù… 53 Ø¨Ù…Ø¯ÙŠÙ†Ø© ØºØ²Ø©.\n",
      "\n",
      "[14] Ø´Ø§Ù‡Ø¯.. Ù‡Ù„ Ø§Ù†ØªÙ‚Ø§Ø¯ Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±ÙŠÙŠÙ† Ù„Ù„Ù…Ø¯Ø±Ø¨ Ø¨ÙŠØªÙƒÙˆÙÙŠØªØ´ Ø­Ø§Ù„Ø© ØµØ­ÙŠØ©ØŸ\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T21:02:26+03:00\n",
      "Ù‚Ø³Ù…: video\n",
      "Ù…Ù„Ø®Øµ: ØªØ³ÙˆØ¯ Ø­Ø§Ù„Ø© Ù…Ù† Ø§Ù„Ø¬Ø¯Ù„ Ø¨Ø§Ù„Ø¬Ø²Ø§Ø¦Ø± Ø­ÙˆÙ„ Ù…ØµÙŠØ± Ù…Ø¯Ø±Ø¨ Ù…Ù†ØªØ®Ø¨ ÙƒØ±Ø© Ø§Ù„Ù‚Ø¯Ù…ØŒ Ø§Ù„Ø³ÙˆÙŠØ³Ø±ÙŠ Ø¨ÙŠØªÙƒÙˆÙÙŠØªØ´ØŒ Ø¨ÙŠÙ† Ù…Ù† ÙŠÙØ¶Ù‘Ù„ Ø§Ø³ØªÙ…Ø±Ø§Ø±Ù‡ ÙÙŠ Ø£Ø¯Ø§Ø¡ Ù…Ù‡Ù…ØªÙ‡ ÙˆØ¨ÙŠÙ† Ù…Ù† ÙŠØ·Ø§Ù„Ø¨ Ø¨Ø¥Ù‚Ø§Ù„ØªÙ‡.\n",
      "\n",
      "[15] Ù…Ø­Ù„Ù„ÙˆÙ†: Ù†ØªÙ†ÙŠØ§Ù‡Ùˆ ÙˆØ¶Ø¹ Ø£Ù…ÙŠØ±ÙƒØ§ Ø¨Ù…Ø£Ø²Ù‚ ÙˆÙ„Ø§ ÙŠØ³ØªØ·ÙŠØ¹ ØªÙƒØ±Ø§Ø± Ø¹Ø¯ÙˆØ§Ù†Ù‡ Ø¹Ù„Ù‰ Ù‚Ø·Ø±\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T20:53:32+03:00\n",
      "Ù‚Ø³Ù…: news\n",
      "Ù…Ù„Ø®Øµ: ÙŠØ¹ØªÙ‚Ø¯ Ù…Ø­Ù„Ù„ÙˆÙ† Ø£Ù† Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ Ù„Ù† ÙŠÙƒÙˆÙ† Ø¨Ù…Ù‚Ø¯ÙˆØ±Ù‡Ø§ ØªÙƒØ±Ø§Ø± Ù…Ø­Ø§ÙˆÙ„ØªÙ‡Ø§ Ø§Ø³ØªÙ‡Ø¯Ø§Ù Ù‚Ø§Ø¯Ø© Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„ÙÙ„Ø³Ø·ÙŠÙ†ÙŠØ© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ÙŠÙ† ÙÙŠ Ø§Ù„Ø¹Ø§ØµÙ…Ø© Ø§Ù„Ù‚Ø·Ø±ÙŠØ© Ø§Ù„Ø¯ÙˆØ­Ø©ØŒ ÙˆØ°Ù„Ùƒ Ø±ØºÙ… Ø§Ù„ØªÙ‡Ø¯ÙŠØ¯ Ø§Ù„Ø°ÙŠ Ø£Ø·Ù„Ù‚Ù‡ Ø¨Ù†ÙŠØ§Ù…ÙŠÙ† Ù†ØªÙ†ÙŠØ§Ù‡Ùˆ.\n",
      "\n",
      "[16] Ø­ÙŠÙ† ØªØµØ¨Ø­ Ø§Ù„Ù…Ù‡Ø§Ø±Ø© Ù‚ÙŠØ¯Ø§.. Ø§Ù„ÙˆØ¬Ù‡ Ø§Ù„Ù…Ø¸Ù„Ù… Ù„Ù„Ø®Ø¨Ø±Ø© ÙÙŠ Ø³ÙˆÙ‚ Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„ÙŠÙˆÙ…\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T20:50:40+03:00\n",
      "Ù‚Ø³Ù…: misc\n",
      "Ù…Ù„Ø®Øµ: Ù„Ùˆ ØªØ¹Ø±Ø¶Øª ÙŠÙˆÙ…Ø§ Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø´Ø§Ù…Ù„Ø© ÙÙŠ Ø§Ù„Ø¹Ù…Ù„ Ø£Ø«Ø±Øª Ø¹Ù„Ù‰ Ù…Ù‡Ø§Ø±ØªÙƒ ÙˆØ¨Ø§Ù„ØªØ§Ù„ÙŠ Ù…ÙƒØ§Ù†ØªÙƒØŒ ÙÙ„Ø±Ø¨Ù…Ø§ ØªÙØªÙ‚Ø± Ù„Ù„Ù…Ø±ÙˆÙ†Ø© Ø§Ù„Ù…Ø¹Ø±ÙÙŠØ©ØŒ ÙÙ…Ø§ Ù‡ÙŠØŸ ÙˆÙƒÙŠÙ Ø£ØµØ¨Ø­ Ø§Ù„ØªÙƒÙŠÙ Ù…Ø¹ÙŠØ§Ø±Ø§ Ù„Ù„Ù†Ø¬Ø§Ø­ ÙÙŠ Ø³ÙˆÙ‚ Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø­Ø¯ÙŠØ«ØŸ\n",
      "\n",
      "[17] ÙŠÙˆÙ… Ø£ÙØ³Ø¯ ØªØºÙŠÙŠØ± Ø§Ù„ÙˆÙƒÙŠÙ„ ØµÙÙ‚Ø© Ø§Ù†Ø¶Ù…Ø§Ù… Ù„Ø§Ù…ÙŠÙ† Ø¬Ù…Ø§Ù„ Ù„Ø¨Ø§ÙŠØ±Ù† Ù…ÙŠÙˆÙ†Ø®\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T20:29:20+03:00\n",
      "Ù‚Ø³Ù…: sport\n",
      "Ù…Ù„Ø®Øµ: ÙƒØ´ÙØª ØµØ­ÙŠÙØ© &quot;Ø¨ÙŠÙ„Ø¯&quot; Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØ©ØŒ Ø£Ù† Ù†Ø§Ø¯ÙŠ Ø¨Ø§ÙŠØ±Ù† Ù…ÙŠÙˆÙ†Ø® Ù„ÙƒØ±Ø© Ø§Ù„Ù‚Ø¯Ù… Ø§Ù‚ØªØ±Ø¨ Ù…Ù† Ø§Ù„ØªØ¹Ø§Ù‚Ø¯ Ù…Ø¹ Ø«Ù†Ø§Ø¦ÙŠ Ø¨Ø±Ø´Ù„ÙˆÙ†Ø© Ù„Ø§Ù…ÙŠÙ† Ø¬Ù…Ø§Ù„ ÙˆØºØ§ÙÙŠ ÙÙŠ Ø¹Ø§Ù… 2022.\n",
      "\n",
      "[18] Ù‚ØªÙŠÙ„ ÙˆØ¬Ø±Ø­Ù‰ Ø¬Ø±Ø§Ø¡ Ù‚ØµÙ \"Ù‚Ø³Ø¯\" Ù‚Ø±Ù‰ Ø¨Ø±ÙŠÙ Ø­Ù„Ø¨ Ø§Ù„Ø´Ø±Ù‚ÙŠ\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T20:20:00+03:00\n",
      "Ù‚Ø³Ù…: news\n",
      "Ù…Ù„Ø®Øµ: Ù‚ØªÙ„ Ù…Ø¯Ù†ÙŠ Ø³ÙˆØ±ÙŠ ÙˆØ£ØµÙŠØ¨ Ø¢Ø®Ø±ÙˆÙ† Ø¨ÙŠÙ†Ù‡Ù… Ø·ÙÙ„ Ø¬Ø±Ø§Ø¡ Ù‚ØµÙ Ù‚ÙˆØ§Øª Ø³ÙˆØ±ÙŠØ§ Ø§Ù„Ø¯ÙŠÙ…Ù‚Ø±Ø§Ø·ÙŠØ© (Ù‚Ø³Ø¯) Ø¨Ø±Ø§Ø¬Ù…Ø§Øª Ø§Ù„ØµÙˆØ§Ø±ÙŠØ® Ù‚Ø±Ù‰ Ø§Ù„ÙƒÙŠØ§Ø±ÙŠØ© (Ø´Ø±Ù‚ÙŠ Ù…Ø¯ÙŠÙ†Ø© Ø­Ù„Ø¨ Ø´Ù…Ø§Ù„ Ø§Ù„Ø¨Ù„Ø§Ø¯) ÙˆØ§Ù„Ø®ÙØ³Ø© ÙˆØ±Ø³Ù… Ø§Ù„Ø£Ø­Ù…Ø±ØŒ ÙˆÙÙ‚ Ù…Ø§ Ø£ÙØ§Ø¯Øª Ù‚Ù†Ø§Ø© Ø§Ù„Ø¥Ø®Ø¨Ø§Ø±ÙŠØ© Ø§Ù„Ø³ÙˆØ±ÙŠØ©.\n",
      "\n",
      "[19] Ø§Ù„Ø¹Ø¯ÙˆØ§Ù† Ø¹Ù„Ù‰ Ù‚Ø·Ø± ÙƒØ´Ù ØºØ¯Ø± Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ ÙˆØ±ÙØ¶Ù‡Ø§ Ù„Ù„Ø³Ù„Ø§Ù…\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T20:12:25+03:00\n",
      "Ù‚Ø³Ù…: video\n",
      "Ù…Ù„Ø®Øµ: ÙƒØ´Ù Ø§Ù„Ø¹Ø¯ÙˆØ§Ù† Ø§Ù„Ø°ÙŠ Ø´Ù†ØªÙ‡ Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ Ø¹Ù„Ù‰ Ø§Ù„ÙˆÙØ¯ Ø§Ù„Ù…ÙØ§ÙˆØ¶ ÙÙŠ Ø­Ø±ÙƒØ© Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ© (Ø­Ù…Ø§Ø³)ØŒ Ø­Ø¬Ù… Ø§Ù„ØºØ¯Ø± Ø§Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠØŒ ÙˆØ¥ØµØ±Ø§Ø± Ù‡Ø°Ù‡ Ø§Ù„Ø¯ÙˆÙ„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±Ø¨ ÙˆØ±ÙØ¶Ù‡Ø§ Ù„Ù„Ø³Ù„Ø§Ù….\n",
      "\n",
      "[20] Ø­Ø§Ø±Ø³ Ù…Ù†ØªØ®Ø¨ ÙØ±Ù†Ø³Ø§ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù…Ø§Ù†Ø¯Ø§Ù†Ø¯Ø§ ÙŠØ¹Ù„Ù† Ø§Ø¹ØªØ²Ø§Ù„Ù‡\n",
      "ØªØ§Ø±ÙŠØ®: 2025-09-10T19:48:10+03:00\n",
      "Ù‚Ø³Ù…: sport\n",
      "Ù…Ù„Ø®Øµ: Ø£Ø¹Ù„Ù† Ø­Ø§Ø±Ø³ Ø§Ù„Ù…Ø±Ù…Ù‰ Ø§Ù„Ø¯ÙˆÙ„ÙŠ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ø³ØªÙŠÙ Ù…Ø§Ù†Ø¯Ø§Ù†Ø¯Ø§ØŒ Ø¨Ø·Ù„ Ø§Ù„Ø¹Ø§Ù„Ù… Ù…Ø¹ Ø§Ù„Ù…Ù†ØªØ®Ø¨ Ø§Ù„ÙØ±Ù†Ø³ÙŠ Ù„ÙƒØ±Ø© Ø§Ù„Ù‚Ø¯Ù… Ø¹Ø§Ù… 2018ØŒ Ø¹Ù† Ø§Ø¹ØªØ²Ø§Ù„Ù‡ Ø§Ù„Ù„Ø¹Ø¨ Ù†Ù‡Ø§Ø¦ÙŠØ§ØŒ ÙˆÙ‡Ùˆ ÙÙŠ Ø§Ù„Ø£Ø±Ø¨Ø¹ÙŠÙ† Ù…Ù† Ø¹Ù…Ø±Ù‡ØŒ ÙÙŠ Ù…Ù‚Ø§Ø¨Ù„Ø© Ù…Ø¹ ØµØ­ÙŠÙØ© &quot;Ù„ÙŠÙƒÙŠØ¨&quot; Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ©.\n",
      "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù: aljazeera_ar_news.csv\n",
      "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù: aljazeera_ar_news.json\n",
      "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù: aljazeera_ar_news.xlsx\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Al Jazeera Arabic news scraper (RSS + fallback HTML scraping)\n",
    "- ÙŠØ¹Ø±Ø¶ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙÙŠ Ø§Ù„Ø·Ø±ÙÙŠØ©\n",
    "- ÙŠØµØ¯Ù‘Ø± Ø¥Ù„Ù‰ CSV Ùˆ JSON (Ùˆ XLSX Ø§Ø®ØªÙŠØ§Ø±ÙŠ)\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ø­Ø§ÙˆÙ„ ØªØ«Ø¨ÙŠØª Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø²Ù… Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©:\n",
    "# pip install requests beautifulsoup4 lxml tqdm feedparser pandas openpyxl\n",
    "\n",
    "try:\n",
    "    import feedparser\n",
    "except ImportError:\n",
    "    feedparser = None\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    pd = None\n",
    "\n",
    "BASE = \"https://www.aljazeera.net\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/127.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Ø¨Ø¹Ø¶ RSS Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© (Ù‚Ø¯ ØªØªØºÙŠØ± Ù…Ø¹ Ø§Ù„ÙˆÙ‚Øª)\n",
    "RSS_FEEDS = [\n",
    "    # ÙƒÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± (Ø¥Ù† ÙˆØ¬Ø¯)\n",
    "    \"https://www.aljazeera.net/rss\",\n",
    "    # Ø§Ù„Ø³ÙŠØ§Ø³Ø©\n",
    "    \"https://www.aljazeera.net/politics/rss\",\n",
    "    # Ø§Ù‚ØªØµØ§Ø¯\n",
    "    \"https://www.aljazeera.net/economy/rss\",\n",
    "    # Ø±ÙŠØ§Ø¶Ø©\n",
    "    \"https://www.aljazeera.net/sports/rss\",\n",
    "    # ØªÙ‚Ø§Ø±ÙŠØ±\n",
    "    \"https://www.aljazeera.net/reports/rss\",\n",
    "]\n",
    "\n",
    "# Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ØªÙŠ Ù†Ø±ÙŠØ¯Ù‡Ø§\n",
    "MAX_ITEMS = 100\n",
    "\n",
    "def normalize_url(link: str) -> str:\n",
    "    if not link:\n",
    "        return \"\"\n",
    "    if link.startswith(\"//\"):\n",
    "        return \"https:\" + link\n",
    "    if link.startswith(\"/\"):\n",
    "        return urljoin(BASE, link)\n",
    "    return link\n",
    "\n",
    "def clean_text(x: str) -> str:\n",
    "    if not x:\n",
    "        return \"\"\n",
    "    return re.sub(r\"\\s+\", \" \", x).strip()\n",
    "\n",
    "def try_parse_date(val: str):\n",
    "    for fmt in (\"%a, %d %b %Y %H:%M:%S %z\",\n",
    "                \"%Y-%m-%dT%H:%M:%S%z\",\n",
    "                \"%Y-%m-%dT%H:%M:%S%zZ\",\n",
    "                \"%Y-%m-%dT%H:%M:%S%zZ\",\n",
    "                \"%Y-%m-%dT%H:%M:%S%z\",\n",
    "                \"%Y-%m-%dT%H:%M:%S\",\n",
    "                \"%Y-%m-%d %H:%M:%S\",\n",
    "                \"%Y-%m-%d\"):\n",
    "        try:\n",
    "            return datetime.strptime(val, fmt)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "def fetch(url):\n",
    "    r = requests.get(url, headers=HEADERS, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    return r\n",
    "\n",
    "def parse_article_html(url: str) -> dict:\n",
    "    \"\"\"Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ (Ø§Ù„Ø¹Ù†ÙˆØ§Ù†ØŒ Ø§Ù„Ù…Ù„Ø®ØµØŒ Ø§Ù„ØªØ§Ø±ÙŠØ®ØŒ Ø§Ù„Ù‚Ø³Ù…) Ù…Ù† ØµÙØ­Ø© Ø®Ø¨Ø± ÙØ±Ø¯ÙŠØ©.\"\"\"\n",
    "    try:\n",
    "        r = fetch(url)\n",
    "    except Exception as e:\n",
    "        return {\"url\": url, \"error\": str(e)}\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "    # Ø§Ù„Ø¹Ù†ÙˆØ§Ù†\n",
    "    title = \"\"\n",
    "    for sel in [\n",
    "        'meta[property=\"og:title\"]',\n",
    "        \"h1\", 'meta[name=\"twitter:title\"]'\n",
    "    ]:\n",
    "        node = soup.select_one(sel)\n",
    "        if node:\n",
    "            title = node.get(\"content\") if node.has_attr(\"content\") else node.get_text()\n",
    "            title = clean_text(title)\n",
    "            if title:\n",
    "                break\n",
    "\n",
    "    # Ø§Ù„ÙˆØµÙ\n",
    "    summary = \"\"\n",
    "    for sel in [\n",
    "        'meta[name=\"description\"]',\n",
    "        'meta[property=\"og:description\"]',\n",
    "        'meta[name=\"twitter:description\"]'\n",
    "    ]:\n",
    "        node = soup.select_one(sel)\n",
    "        if node and node.get(\"content\"):\n",
    "            summary = clean_text(node[\"content\"])\n",
    "            if summary:\n",
    "                break\n",
    "\n",
    "    # Ø§Ù„ØªØ§Ø±ÙŠØ®\n",
    "    pub = \"\"\n",
    "    for sel in [\n",
    "        'meta[property=\"article:published_time\"]',\n",
    "        'meta[property=\"og:updated_time\"]',\n",
    "        'time[datetime]'\n",
    "    ]:\n",
    "        node = soup.select_one(sel)\n",
    "        if node:\n",
    "            pub = node.get(\"content\") or node.get(\"datetime\") or \"\"\n",
    "            pub = clean_text(pub)\n",
    "            if pub:\n",
    "                break\n",
    "    pub_dt = try_parse_date(pub) if pub else None\n",
    "    pub_str = pub_dt.isoformat() if pub_dt else pub\n",
    "\n",
    "    # Ø§Ù„Ù‚Ø³Ù… Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø£Ùˆ ÙØªØ§Øª Ø§Ù„ØªÙ†Ù‚Ù„\n",
    "    parsed = urlparse(url)\n",
    "    category = \"\"\n",
    "    parts = [p for p in parsed.path.split(\"/\") if p]\n",
    "    if parts:\n",
    "        # Ù…Ø«Ø§Ù„: /politics/2025/9/10/slug\n",
    "        category = parts[0]\n",
    "\n",
    "    return {\n",
    "        \"title\": title or \"\",\n",
    "        \"summary\": summary or \"\",\n",
    "        \"published\": pub_str or \"\",\n",
    "        \"category\": category or \"\",\n",
    "        \"url\": url\n",
    "    }\n",
    "\n",
    "def scrape_homepage(max_links=50) -> list:\n",
    "    \"\"\"Ø®Ø·Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: Ù†Ø¬Ù…Ø¹ Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙˆØ¨Ø¹Ø¶ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©.\"\"\"\n",
    "    items = []\n",
    "    seen = set()\n",
    "\n",
    "    def collect_from(page_url):\n",
    "        try:\n",
    "            r = fetch(page_url)\n",
    "        except Exception:\n",
    "            return\n",
    "        soup = BeautifulSoup(r.text, \"lxml\")\n",
    "        # Ø§Ù„ØªÙ‚Ø· ÙƒÙ„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ø¥Ù„Ù‰ Ù…Ù‚Ø§Ù„Ø§Øª\n",
    "        for a in soup.find_all(\"a\", href=True):\n",
    "            href = normalize_url(a[\"href\"])\n",
    "            if not href.startswith(BASE):\n",
    "                continue\n",
    "            if any(x in href for x in [\"video\", \"live\", \"programs\"]):\n",
    "                continue\n",
    "            if re.search(r\"/\\d{4}/\\d{1,2}/\\d{1,2}/\", href):  # ÙŠØ­ØªÙˆÙŠ ØªØ§Ø±ÙŠØ® ÙÙŠ Ø§Ù„Ø±Ø§Ø¨Ø·\n",
    "                if href not in seen:\n",
    "                    seen.add(href)\n",
    "                    items.append(href)\n",
    "\n",
    "    # Ø§Ø¨Ø¯Ø£ Ø¨Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙˆØ¨Ø¹Ø¶ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©\n",
    "    seeds = [\n",
    "        BASE,\n",
    "        f\"{BASE}/politics\",\n",
    "        f\"{BASE}/economy\",\n",
    "        f\"{BASE}/sports\",\n",
    "        f\"{BASE}/news\",\n",
    "        f\"{BASE}/reports\",\n",
    "        f\"{BASE}/opinions\",\n",
    "    ]\n",
    "    for s in seeds:\n",
    "        collect_from(s)\n",
    "        time.sleep(1)\n",
    "        if len(items) >= max_links:\n",
    "            break\n",
    "\n",
    "    items = items[:max_links]\n",
    "    results = []\n",
    "    for link in tqdm(items, desc=\"Parsing articles (HTML fallback)\"):\n",
    "        data = parse_article_html(link)\n",
    "        results.append(data)\n",
    "        time.sleep(0.8)  # Ù„Ø·ÙØ§Ù‹ Ø¨Ø§Ù„Ø®Ø§Ø¯Ù…\n",
    "    return results\n",
    "\n",
    "def read_via_rss(max_items=MAX_ITEMS) -> list:\n",
    "    \"\"\"Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¹Ø¨Ø± RSS (Ø§Ù„Ø£ÙØ¶Ù„ Ø¥Ù† ØªÙˆÙØ±).\"\"\"\n",
    "    if feedparser is None:\n",
    "        return []\n",
    "\n",
    "    collected = []\n",
    "    seen_links = set()\n",
    "    for feed in RSS_FEEDS:\n",
    "        try:\n",
    "            d = feedparser.parse(feed)\n",
    "        except Exception:\n",
    "            continue\n",
    "        for e in d.entries:\n",
    "            link = normalize_url(getattr(e, \"link\", \"\"))\n",
    "            if not link or link in seen_links:\n",
    "                continue\n",
    "            seen_links.add(link)\n",
    "\n",
    "            title = clean_text(getattr(e, \"title\", \"\"))\n",
    "            summary = clean_text(getattr(e, \"summary\", \"\")) or clean_text(getattr(e, \"description\", \"\"))\n",
    "            published = \"\"\n",
    "            if getattr(e, \"published\", \"\"):\n",
    "                published = e.published\n",
    "            elif getattr(e, \"updated\", \"\"):\n",
    "                published = e.updated\n",
    "\n",
    "            # Ø¬Ø±Ù‘Ø¨ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ®\n",
    "            pub_dt = try_parse_date(published) if published else None\n",
    "            pub_str = pub_dt.isoformat() if pub_dt else published\n",
    "\n",
    "            # Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ù‚Ø³Ù… Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·\n",
    "            parsed = urlparse(link)\n",
    "            parts = [p for p in parsed.path.split(\"/\") if p]\n",
    "            category = parts[0] if parts else \"\"\n",
    "\n",
    "            collected.append({\n",
    "                \"title\": title,\n",
    "                \"summary\": summary,\n",
    "                \"published\": pub_str,\n",
    "                \"category\": category,\n",
    "                \"url\": link\n",
    "            })\n",
    "            if len(collected) >= max_items:\n",
    "                break\n",
    "        if len(collected) >= max_items:\n",
    "            break\n",
    "\n",
    "    return collected\n",
    "\n",
    "def export_data(rows: list, basename=\"aljazeera_ar_news\"):\n",
    "    if not rows:\n",
    "        print(\"Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØµØ¯ÙŠØ±Ù‡Ø§.\")\n",
    "        return\n",
    "\n",
    "    # CSV\n",
    "    csv_name = f\"{basename}.csv\"\n",
    "    with open(csv_name, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=[\"title\", \"summary\", \"published\", \"category\", \"url\"])\n",
    "        w.writeheader()\n",
    "        for r in rows:\n",
    "            w.writerow(r)\n",
    "    print(f\"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù: {csv_name}\")\n",
    "\n",
    "    # JSON\n",
    "    json_name = f\"{basename}.json\"\n",
    "    with open(json_name, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(rows, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù: {json_name}\")\n",
    "\n",
    "    # Excel (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)\n",
    "    if pd is not None:\n",
    "        try:\n",
    "            xlsx_name = f\"{basename}.xlsx\"\n",
    "            df = pd.DataFrame(rows)\n",
    "            df.to_excel(xlsx_name, index=False)\n",
    "            print(f\"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù: {xlsx_name}\")\n",
    "        except Exception as e:\n",
    "            print(\"ØªØ¹Ø°Ø± Ø¥Ù†Ø´Ø§Ø¡ Excel:\", e)\n",
    "    else:\n",
    "        print(\"Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ExcelØŒ Ø«Ø¨Ù‘Øª pandas Ùˆ openpyxl.\")\n",
    "\n",
    "def main():\n",
    "    print(\"ğŸ” Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: RSS ...\")\n",
    "    news = read_via_rss(max_items=MAX_ITEMS)\n",
    "\n",
    "    if not news:\n",
    "        print(\"ğŸ” Ù„Ù… ÙŠÙ†Ø¬Ø­ RSSØŒ Ø³Ù†Ø­Ø§ÙˆÙ„ Web Scraping Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù…Ù† Ø§Ù„ØµÙØ­Ø§Øª...\")\n",
    "        news = scrape_homepage(max_links=MAX_ITEMS)\n",
    "\n",
    "    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙØ±Ø§ØºØ§Øª ÙˆØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¥Ù† Ø£Ù…ÙƒÙ†\n",
    "    for n in news:\n",
    "        n[\"title\"] = clean_text(n.get(\"title\", \"\"))\n",
    "        n[\"summary\"] = clean_text(n.get(\"summary\", \"\"))\n",
    "        n[\"category\"] = clean_text(n.get(\"category\", \"\"))\n",
    "        n[\"url\"] = clean_text(n.get(\"url\", \"\"))\n",
    "\n",
    "    # Ø·Ø¨Ø§Ø¹Ø© Ø£ÙˆÙ„ 20 Ø®Ø¨Ø± Ù„Ù„Ù…Ø¹Ø§ÙŠÙ†Ø©\n",
    "    print(\"\\n=== Ø£Ø­Ø¯Ø« Ø§Ù„Ø£Ø®Ø¨Ø§Ø± (Ø£ÙˆÙ„ 20) ===\")\n",
    "    for i, item in enumerate(news[:20], 1):\n",
    "        print(f\"\\n[{i}] {item.get('title','')}\")\n",
    "        if item.get(\"published\"):\n",
    "            print(f\"ØªØ§Ø±ÙŠØ®: {item['published']}\")\n",
    "        if item.get(\"category\"):\n",
    "            print(f\"Ù‚Ø³Ù…: {item['category']}\")\n",
    "        if item.get(\"summary\"):\n",
    "            print(f\"Ù…Ù„Ø®Øµ: {item['summary'][:220]}{'...' if len(item['summary'])>220 else ''}\")\n",
    "\n",
    "    # ØªØµØ¯ÙŠØ±\n",
    "    export_data(news)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ØªØ°ÙƒÙŠØ± Ø£Ø®Ù„Ø§Ù‚ÙŠ:\n",
    "    # âœ”ï¸ Ø±Ø§Ø¬Ø¹ Ø´Ø±ÙˆØ· Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ùˆ robots.txt\n",
    "    # âœ”ï¸ Ø§Ø³ØªØ®Ø¯Ù… ØªØ£Ø®ÙŠØ±Ø§Ù‹ Ø¨ÙŠÙ† Ø§Ù„Ø·Ù„Ø¨Ø§Øª ÙˆÙ„Ø§ ØªØ¨Ø§Ù„Øº ÙÙŠ Ø¹Ø¯Ø¯Ù‡Ø§\n",
    "    # âœ”ï¸ Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯ ØªØ¹Ù„ÙŠÙ…ÙŠØ› Ù‚Ø¯ ÙŠÙ„Ø²Ù… ØªØ¹Ø¯ÙŠÙ„Ù‡ Ø¥Ø°Ø§ ØªØºÙŠÙ‘Ø± Ø¨Ù†Ø§Ø¡ ØµÙØ­Ø§Øª Ø§Ù„Ù…ÙˆÙ‚Ø¹\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nØªÙ… Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….\")\n",
    "    except Exception as e:\n",
    "        print(\"Ø­Ø¯Ø« Ø®Ø·Ø£:\", e, file=sys.stderr)\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
